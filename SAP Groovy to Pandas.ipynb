{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T08:12:18.107210Z",
     "start_time": "2019-11-08T08:12:18.104337Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as et \n",
    "import os\n",
    "import regex as re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:22:57.659399Z",
     "start_time": "2019-11-08T11:22:57.493123Z"
    }
   },
   "outputs": [],
   "source": [
    "groovylist = []\n",
    "for root, dirs, files in os.walk(\"../../../Downloads/PostNLQAS\"):\n",
    "    groovylist = groovylist + glob.glob(root+'/*.groovy')\n",
    "    groovylist = groovylist + glob.glob(root+'/*.gsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T13:04:43.530138Z",
     "start_time": "2019-11-08T13:04:43.525725Z"
    }
   },
   "outputs": [],
   "source": [
    "comments = r'(\\/\\*[ -}\\n\\s]*?\\*\\/)'\n",
    "comments2 = r'\\/\\/.+'\n",
    "defines = r'def.?{\\n[ -z\\n\\t\\;\\=\\.\\(]*\\}'\n",
    "imports = r'import.*?\\n]'\n",
    "linecount = r'\\n'\n",
    "whitelines = r'^([\\n\\s]*)$' #multiline\n",
    "commentcount = r'\\/\\/.*?\\n'\n",
    "reglist = [{'regex':comments, 'flag':False, 'name':\"comments\"},\n",
    "#           {'regex':functions, 'flag':False, 'name':\"defines\"},\n",
    "#           {'regex':imports, 'flag':False, 'name':\"imports\"},\n",
    "#           {'regex':linecount, 'flag':False, 'name':\"linecount\"},\n",
    "          {'regex':whitelines, 'flag':True, 'name':\"whitelines\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T13:04:44.173433Z",
     "start_time": "2019-11-08T13:04:44.074159Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"filepath\":[],\"comments\":[],\"singlelinecomments\":[],\"defines\":[],\"imports\":[],\"linecount\":[],\"whitelines\":[],\"linesofcode\":[]}\n",
    "for filename in groovylist:\n",
    "    with open(filename, 'r') as file:\n",
    "        filecontent = file.readlines()\n",
    "        linesum = sum(1 for line in filecontent)\n",
    "        filestrcontent = str(filecontent)\n",
    "#         linesum += len(filecontent)\n",
    "        importcount = filestrcontent.count(\"import\")\n",
    "        defcount = filestrcontent.count(\"def\")\n",
    "        singlelinecommentcount = filestrcontent.count(\"//\")\n",
    "        for reg in reglist:\n",
    "#             print(reg)\n",
    "            match = None\n",
    "            if reg['flag']:\n",
    "                match = []\n",
    "                for line in filecontent:\n",
    "                    match += re.findall(r'^([\\n\\s]*)$', line)\n",
    "#                 print(match)\n",
    "            else:\n",
    "                match = re.findall(reg['regex'], filestrcontent)\n",
    "            if not match == []:\n",
    "                if reg['flag']:\n",
    "                    data[reg['name']].append(len(match))\n",
    "                else:\n",
    "                    if reg['name'] == \"comments\":\n",
    "                        res = re.search(reg['regex'],filestrcontent)\n",
    "                        match = str(res.group(1))\n",
    "                        match = ' '.join([str(elem) for elem in match.split(\"', '\")])\n",
    "                        match = re.sub(r'\\/\\/.+?\\\\n', \" \", match)\n",
    "                        match = ' '.join([str(elem) for elem in match.split(\"', '\")])\n",
    "                        match = re.sub(r'\\\\n \\\\n', \"\\n\", match)\n",
    "                        match = ' '.join([str(elem) for elem in match.split(\"', '\")])\n",
    "                        match = re.sub(r'\\\\n', \"\\n\", match)\n",
    "                        match = re.findall(r'\\n',match)\n",
    "                    else:\n",
    "                        match = match[0].split(',')\n",
    "        #                 print(len(match.groups()))\n",
    "                    data[reg['name']].append(len(match))\n",
    "            else:\n",
    "                data[reg['name']].append(0)\n",
    "        data['filepath'].append(filename)\n",
    "        data['imports'].append(importcount)\n",
    "        data['defines'].append(defcount)\n",
    "        data['linecount'].append(linesum)\n",
    "        data['singlelinecomments'].append(singlelinecommentcount)\n",
    "#         data['linesofcode'].append((data['linecount'][-1]-data['comments'][-1]-data['whitelines'][-1]-data['singlelinecomments'][-1]))\n",
    "#         print(len(filecontent))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data['imports'])):\n",
    "    data['linesofcode'].append((data['linecount'][i]-data['comments'][i]-data['whitelines'][i]-data['singlelinecomments'][i]))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groovylist[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['linecount'][37],data['comments'][37],data['whitelines'][37],data['singlelinecomments'][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotesis, Lines of code and imports are high indicators for the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../generateddata/qasgroovy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedBlockDepth.xml\n",
      "ParameterCount.xml\n",
      "GroovyOverlyComplexMethod.xml\n",
      "AbcMetric.xml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "prefix = \"../../../Downloads/FinalQASMetrics/\"\n",
    "\n",
    "metricslist = []\n",
    "df_cols = [\"metric\",\"file\", \"line\",\"problem_class\",\"problem_severity\",\"description\"]\n",
    "rows = []\n",
    "for root, dirs, files in os.walk(prefix):\n",
    "    for i in files:\n",
    "        print(i)\n",
    "        metric = i\n",
    "        xtree = et.parse(prefix+i)\n",
    "        problems = xtree.getroot() \n",
    "        for node in list(problems): \n",
    "            file = node.find(\"file\").text if node is not None else None\n",
    "            line = node.find(\"line\").text if node is not None else None\n",
    "            package = node.find(\"package\").text if node is not None else None\n",
    "            problem_class = node.find(\"problem_class\").text if node is not None else None\n",
    "            problem_severity = node.find(\"problem_class\").attrib.get(\"severity\") if node is not None else None\n",
    "            description = node.find(\"description\").text if node is not None else None\n",
    "\n",
    "            file = file.replace(\"file://$PROJECT_DIR$\", \"../../../Downloads/PostNLQAS\")\n",
    "            rows.append({\"metric\":metric,\"file\": file, \"line\": line, \n",
    "                        \"problem_class\": problem_class,\n",
    "                        \"problem_severity\":problem_severity,\"description\":description})\n",
    "        \n",
    "\n",
    "out_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcscore(x):\n",
    "    regexexpression = r\".+?([\\d\\.]{3,5}).+\"\n",
    "    res = re.search(regexexpression, x)\n",
    "    if res:\n",
    "        return res.group(1)\n",
    "    return None\n",
    "\n",
    "def cyclomaticcomplexity(x):\n",
    "    regexexpression = r\"\\=(\\d{1,2})+\"\n",
    "    res = re.search(regexexpression, x)\n",
    "    if res:\n",
    "        return res.group(1)\n",
    "    return None\n",
    "\n",
    "def nestedblock(x):\n",
    "    regexexpression = r\".+?([\\d]+)\"\n",
    "    res = re.search(regexexpression, x)\n",
    "    if res:\n",
    "        return res.group(1)\n",
    "    return None\n",
    "\n",
    "def ParameterCount(x):\n",
    "    regexexpression = r\".+?([\\d]+).+\"\n",
    "    res = re.search(regexexpression, x)\n",
    "    if res:\n",
    "        return res.group(1)\n",
    "    return None\n",
    "\n",
    "def formatter(metric, x):\n",
    "    if metric == 'NestedBlockDepth.xml':\n",
    "        return nestedblock(x)\n",
    "    elif metric == 'ParameterCount.xml':\n",
    "        return ParameterCount(x)\n",
    "    elif metric == 'GroovyOverlyComplexMethod.xml':\n",
    "        return cyclomaticcomplexity(x)\n",
    "    elif metric == 'AbcMetric.xml':\n",
    "        return abcscore(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_df = out_df[out_df['metric']==\"NestedBlockDepth.xml\"]\n",
    "nested_df['nestedscore'] = nested_df.apply(lambda row: formatter(row['metric'],row['description']), axis=1)\n",
    "nested_df = nested_df.drop(columns=[\"metric\", \"line\", \"problem_severity\", \"description\", \"problem_class\"])\n",
    "for file in nested_df['file'].unique():\n",
    "    values = nested_df[nested_df['file']==file].nestedscore.values\n",
    "    val = np.amax(values)\n",
    "    nested_df.loc[nested_df['file'] == file, ['nestedscore']] = val\n",
    "nested_df = nested_df.drop_duplicates()\n",
    "nested_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = out_df[out_df['metric']==\"ParameterCount.xml\"]\n",
    "param_df['paramscore'] = param_df.apply(lambda row: formatter(row['metric'],row['description']), axis=1)\n",
    "param_df = param_df.drop(columns=[\"metric\", \"line\", \"problem_severity\", \"description\", \"problem_class\"])\n",
    "for file in param_df['file'].unique():\n",
    "    values = param_df[param_df['file']==file].paramscore.values\n",
    "    val = np.amax(values)\n",
    "    param_df.loc[param_df['file'] == file, ['paramscore']] = val\n",
    "param_df = param_df.drop_duplicates()\n",
    "param_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclo_df = out_df[out_df['metric']==\"GroovyOverlyComplexMethod.xml\"]\n",
    "cyclo_df['cycloscore'] = cyclo_df.apply(lambda row: formatter(row['metric'],row['description']), axis=1)\n",
    "cyclo_df = cyclo_df.drop(columns=[\"metric\", \"line\", \"problem_severity\", \"description\", \"problem_class\"])\n",
    "for file in cyclo_df['file'].unique():\n",
    "    values = cyclo_df[cyclo_df['file']==file].cycloscore.values\n",
    "    val = np.amax(values)\n",
    "    cyclo_df.loc[cyclo_df['file'] == file, ['cycloscore']] = val\n",
    "cyclo_df = cyclo_df.drop_duplicates()\n",
    "cyclo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_df = out_df[out_df['metric']==\"AbcMetric.xml\"]\n",
    "abc_df['abcscore'] = abc_df.apply(lambda row: formatter(row['metric'],row['description']), axis=1)\n",
    "abc_df = abc_df.drop(columns=[\"metric\", \"line\", \"problem_severity\", \"description\", \"problem_class\"])\n",
    "for file in abc_df['file'].unique():\n",
    "    values = abc_df[abc_df['file']==file].abcscore.values\n",
    "    val = np.amax(values)\n",
    "    abc_df.loc[abc_df['file'] == file, ['abcscore']] = val\n",
    "cyclo_df = cyclo_df.drop_duplicates()\n",
    "abc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['description'][29]\n",
    "df = df.rename(mapper={\"filepath\":\"file\"}, axis=\"columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat([df, abc_df, cyclo_df, param_df, nested_df])\n",
    "finaldf = finaldf.fillna(value=0)\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv(\"../generateddata/qasgroovymetrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2805 entries, 0 to 265\n",
      "Data columns (total 12 columns):\n",
      "abcscore              644 non-null object\n",
      "comments              1768 non-null float64\n",
      "cycloscore            161 non-null object\n",
      "defines               1768 non-null float64\n",
      "file                  2805 non-null object\n",
      "imports               1768 non-null float64\n",
      "linecount             1768 non-null float64\n",
      "linesofcode           1768 non-null float64\n",
      "nestedscore           45 non-null object\n",
      "paramscore            187 non-null object\n",
      "singlelinecomments    1768 non-null float64\n",
      "whitelines            1768 non-null float64\n",
      "dtypes: float64(7), object(5)\n",
      "memory usage: 284.9+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}